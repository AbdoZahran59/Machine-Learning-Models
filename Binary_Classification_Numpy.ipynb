{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVDcr8Nj_w2D",
        "outputId": "6f13cd38-ca1e-4f2f-cb8b-aaa2113f15e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.6931471803599452\n",
            "Cost after iteration 100: 0.44230451922986835\n",
            "Cost after iteration 200: 0.3693142629092678\n",
            "Cost after iteration 300: 0.33389346068100284\n",
            "Cost after iteration 400: 0.31243836721222806\n",
            "Cost after iteration 500: 0.2977328577588806\n",
            "Cost after iteration 600: 0.2868352380012465\n",
            "Cost after iteration 700: 0.2783211332270439\n",
            "Cost after iteration 800: 0.27141538984796443\n",
            "Cost after iteration 900: 0.26565813031476715\n",
            "Model Evaluation:\n",
            "Training Accuracy: 91.70%\n",
            "Testing Accuracy: 58.07%\n",
            "Summary of Predicted and Actual Values:\n",
            "Training Set:\n",
            "Predicted   Actual\n",
            "1           1\n",
            "1           1\n",
            "1           1\n",
            "1           1\n",
            "1           1\n",
            "...\n",
            "0           0\n",
            "0           0\n",
            "0           0\n",
            "1           0\n",
            "0           0\n",
            "\n",
            "Testing Set:\n",
            "Predicted   Actual\n",
            "0           0\n",
            "0           0\n",
            "0           0\n",
            "0           0\n",
            "0           0\n",
            "...\n",
            "0           0\n",
            "1           0\n",
            "0           0\n",
            "0           0\n",
            "0           0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# Load the dataset from URL\n",
        "def load_data_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    data = StringIO(response.text)\n",
        "    df = pd.read_csv(data, header=None)\n",
        "    X = df.iloc[:, :-1].values\n",
        "    y = df.iloc[:, -1].values\n",
        "    return X, y\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Initialize parameters\n",
        "def initialize_parameters(n_features):\n",
        "    return np.zeros((n_features, 1)), 0\n",
        "\n",
        "# Compute cost and gradients\n",
        "def compute_cost_and_gradients(X, y, W, b):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    # Manually implemented sigmoid function\n",
        "    def custom_sigmoid(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    A = custom_sigmoid(np.dot(X, W) + b)\n",
        "\n",
        "    # Add epsilon to avoid taking the logarithm of zero\n",
        "    epsilon = 1e-10\n",
        "    cost = -1/m * np.sum(y * np.log(A + epsilon) + (1 - y) * np.log(1 - A + epsilon))\n",
        "\n",
        "    dW = 1/m * np.dot(X.T, (A - y))\n",
        "    db = 1/m * np.sum(A - y)\n",
        "\n",
        "    return cost, dW, db\n",
        "\n",
        "# Train the model\n",
        "def train_model(X, y, learning_rate, num_iterations):\n",
        "    n_features = X.shape[1]\n",
        "    W, b = initialize_parameters(n_features)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        cost, dW, db = compute_cost_and_gradients(X, y, W, b)\n",
        "\n",
        "        # Update parameters\n",
        "        W -= learning_rate * dW\n",
        "        b -= learning_rate * db\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f'Cost after iteration {i}: {cost}')\n",
        "\n",
        "    return W, b\n",
        "\n",
        "# Predict function\n",
        "def predict(X, W, b):\n",
        "    # Manually implemented sigmoid function\n",
        "    def custom_sigmoid(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    A = custom_sigmoid(np.dot(X, W) + b)\n",
        "    return (A > 0.5).astype(int)\n",
        "\n",
        "# Feature scaling\n",
        "def scale_features(X):\n",
        "    mean = np.mean(X, axis=0)\n",
        "    std = np.std(X, axis=0)\n",
        "    X_scaled = (X - mean) / std\n",
        "    return X_scaled\n",
        "\n",
        "# Define learning rate and epochs\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "\n",
        "# Define the URL of the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "\n",
        "# Load the data from the URL\n",
        "X, y = load_data_from_url(url)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "split_index = 4000  # Adjust this according to your dataset size and split ratio\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "# Scale features\n",
        "X_train_scaled = scale_features(X_train)\n",
        "X_test_scaled = scale_features(X_test)\n",
        "\n",
        "# Train the model using scaled features\n",
        "W, b = train_model(X_train_scaled, y_train.reshape(-1, 1), learning_rate, num_iterations)\n",
        "\n",
        "# Make predictions using scaled features\n",
        "y_pred_train = predict(X_train_scaled, W, b)\n",
        "y_pred_test = predict(X_test_scaled, W, b)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_train = np.mean(y_pred_train == y_train.reshape(-1, 1)) * 100\n",
        "accuracy_test = np.mean(y_pred_test == y_test.reshape(-1, 1)) * 100\n",
        "\n",
        "# Print summary of results\n",
        "print(\"Model Evaluation:\")\n",
        "print(f\"Training Accuracy: {accuracy_train:.2f}%\")\n",
        "print(f\"Testing Accuracy: {accuracy_test:.2f}%\")\n",
        "\n",
        "# Print summary of predicted and actual values\n",
        "print(\"Summary of Predicted and Actual Values:\")\n",
        "print(\"Training Set:\")\n",
        "print(\"Predicted   Actual\")\n",
        "for pred, actual in zip(y_pred_train[:5], y_train[:5]):\n",
        "    print(f\"{pred[0]}           {actual}\")\n",
        "print(\"...\")\n",
        "for pred, actual in zip(y_pred_train[-5:], y_train[-5:]):\n",
        "    print(f\"{pred[0]}           {actual}\")\n",
        "\n",
        "print(\"\\nTesting Set:\")\n",
        "print(\"Predicted   Actual\")\n",
        "for pred, actual in zip(y_pred_test[:5], y_test[:5]):\n",
        "    print(f\"{pred[0]}           {actual}\")\n",
        "print(\"...\")\n",
        "for pred, actual in zip(y_pred_test[-5:], y_test[-5:]):\n",
        "    print(f\"{pred[0]}           {actual}\")\n"
      ]
    }
  ]
}